{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huge Tensor Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "I'm running this on the standard \n",
    "[RAPIDS docker containers](https://hub.docker.com/r/rapidsai/rapidsai) and also\n",
    "need the following `pip` dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.0.1 in /conda/envs/rapids/lib/python3.6/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytorch-ignite==0.1.2 in /conda/envs/rapids/lib/python3.6/site-packages (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.0.1 pytorch-ignite==0.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this on your local machine you should have most things installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "#import dask\n",
    "#from dask.delayed import delayed\n",
    "#from dask.distributed import as_completed, Client, wait\n",
    "#from dask_cuda import LocalCUDACluster\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.handlers import EarlyStopping as IgniteEarlyStopping\n",
    "from ignite.metrics import Loss, Metric\n",
    "#import numpy as np\n",
    "#import pyarrow.parquet as pq\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as torch_optim\n",
    "from torch.utils import data as torch_data\n",
    "\n",
    "# CUDF_VERSION = tuple(map(int, cudf.__version__.split(\".\")[:3]))\n",
    "# assert CUDF_VERSION >= (0, 6, 0), \"cudf version must be at least 0.6.0! Found {}!\".format(CUDF_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.dlpack import from_dlpack, to_dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from librmm_cffi import librmm_config as rmm_cfg\n",
    "#rmm_cfg.use_pool_allocator = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cudf\n",
    "#cudf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyarrow\n",
    "#pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETL - Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_quantiles = 20  # Used for computing histograms of continuous features\n",
    "num_features = 2 ** 22  # When hashing features range will be [0, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_dims = [600,600,600,600]\n",
    "\n",
    "device = 'cuda'\n",
    "dropout = None  # Can add dropout probability in [0, 1] here\n",
    "activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10000000\n",
    "\n",
    "train_batch_size = 2048\n",
    "validation_batch_size = train_batch_size*2\n",
    "\n",
    "log_interval = 100*2048//train_batch_size\n",
    "\n",
    "learning_rate = 0.01\n",
    "patience = 4\n",
    "lr_multiplier = 0.5\n",
    "max_epochs = 3  # Increase this for a more realistic training run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_hidden_layer(in_dim, out_dim, activation, dropout=None):\n",
    "    if dropout:\n",
    "        return nn.Sequential(nn.Linear(in_dim, out_dim), activation, nn.Dropout(p=dropout))\n",
    "    return nn.Sequential(nn.Linear(in_dim, out_dim), activation)\n",
    "\n",
    "\n",
    "class MortgageNetwork(nn.Module):\n",
    "    \"\"\"Mortgage Delinquency DNN.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        embedding_size,\n",
    "        hidden_dims,\n",
    "        use_cuda=True,\n",
    "        activation=nn.ReLU(),\n",
    "        dropout=None,\n",
    "        embedding_bag_mode='mean'\n",
    "    ):\n",
    "        super(MortgageNetwork, self).__init__()\n",
    "        self.input_size = num_features\n",
    "        self.embedding_size = embedding_size\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.modules.EmbeddingBag(self.input_size, self.embedding_size,\n",
    "                                                 mode=embedding_bag_mode)\n",
    "\n",
    "        if len(hidden_dims) > 0:\n",
    "            dims = [self.embedding_size] + hidden_dims\n",
    "            hidden_layers = [\n",
    "                _make_hidden_layer(dims[i], dims[i + 1], self.activation, self.dropout)\n",
    "                for i in range(len(dims) - 1)\n",
    "            ]\n",
    "            self.hidden_layers = nn.ModuleList(hidden_layers)\n",
    "            self.hidden_layers.extend([nn.Linear(dims[-1], 1)])\n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        out = self.embedding(x)\n",
    "        out = self.activation(out)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, batch_dataload=False, num_workers=0, use_cuDF=False):\n",
    "    # Data\n",
    "    if batch_dataload:\n",
    "        train_dataset = load_torch_dataset(os.path.join(out_dir, \"train\"), epoch_size,\n",
    "                                         batch_size=train_batch_size, use_cuDF=use_cuDF, num_files=1)\n",
    "#         validation_dataset = load_torch_dataset(os.path.join(out_dir, \"validation\"),\n",
    "#                                              batch_size=validation_batch_size, use_cuDF=use_cuDF, num_files=None)\n",
    "#         test_dataset = load_torch_dataset(os.path.join(out_dir, \"test\"),\n",
    "#                                              batch_size=validation_batch_size, use_cuDF=use_cuDF, num_files=None)\n",
    "\n",
    "        #train_loader = torch_data.DataLoader(train_dataset,\n",
    "        train_loader = batch_dataloader.BatchDataLoader(train_dataset,\n",
    "                                         num_workers=0, shuffle=True)\n",
    "#         validation_loader = batch_dataloader.BatchDataLoader(validation_dataset,\n",
    "#                                              num_workers=0)\n",
    "#         test_loader = batch_dataloader.BatchDataLoader(test_dataset,\n",
    "#                                             num_workers=0)\n",
    "    else:\n",
    "        train_dataset = load_torch_dataset(os.path.join(out_dir, \"train\"), epoch_size, shuffle_files=False)\n",
    "        validation_dataset = load_torch_dataset(os.path.join(out_dir, \"validation\"))\n",
    "        test_dataset = load_torch_dataset(os.path.join(out_dir, \"test\"))\n",
    "\n",
    "        train_loader = torch_data.DataLoader(train_dataset,\n",
    "                                         batch_size=train_batch_size,\n",
    "                                         num_workers=num_workers)\n",
    "        validation_loader = torch_data.DataLoader(validation_dataset,\n",
    "                                             batch_size=validation_batch_size,\n",
    "                                             num_workers=num_workers)\n",
    "        test_loader = torch_data.DataLoader(test_dataset,\n",
    "                                            batch_size=validation_batch_size,\n",
    "                                            num_workers=num_workers)        \n",
    "    # Optimizer\n",
    "    optimizer = torch_optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Loss Function\n",
    "    loss_fn = lambda pred, target: F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    trainer = create_supervised_trainer(model=model, optimizer=optimizer, loss_fn=loss_fn, device=device)\n",
    "\n",
    "    # Events\n",
    "    @trainer.on(Events.EPOCH_STARTED)\n",
    "    def timer(engine):\n",
    "        setattr(engine.state, \"epoch_start\", time.time())\n",
    "\n",
    "    num_epoch_batches = len(train_loader)\n",
    "    examples_per_epoch = num_epoch_batches * train_batch_size\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        iter = (engine.state.iteration - 1) % num_epoch_batches + 1\n",
    "        if iter % log_interval == 0:\n",
    "            epoch_time_elapsed = time.time() - engine.state.epoch_start\n",
    "            examples = engine.state.iteration * train_batch_size\n",
    "            epoch_examples_per_second = (examples - (engine.state.epoch - 1) * examples_per_epoch) / epoch_time_elapsed\n",
    "            print(\n",
    "                \"Epoch[{}] Iteration[{}/{}] Loss: {:.5f} Example/s: {:.3f} (Total examples: {})\".format(\n",
    "                    engine.state.epoch, iter, num_epoch_batches, engine.state.output,\n",
    "                    epoch_examples_per_second, examples))\n",
    "\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to load large dataset into GPU memory (Random LongTensor)\n",
    "Each load_torch_dataset function below represents a test I did to narrow down the cause of the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_dataset, batch_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial test: Create a dataset of random tensors that fit the model (45 wide longtensor, 1 wide float tensor target)\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.RandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary test: Splitting the single tensor into 3 tensors removes the issue\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.MultiRandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third test: Concatenating the three tensors in the second test into a single tensor.  Issue shows up again\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.ConcatRandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = MortgageNetwork(num_features, embedding_size, hidden_dims,\n",
    "                        dropout=dropout, activation=activation, use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance issue\n",
    "Slowdown occurs around 12M examples.  Examples/s start getting slower and even when the epoch resets to access the memory that used to be fast performance is still poor and continues to degrade.\n",
    "\n",
    "You can see epoch 2 is about 1/2 as fast and performance keeps getting worse.\n",
    "\n",
    "I've tried to offset the dataloader so that it starts in that memory region and the slowdown is immediate and starts at around 25K examples/s, even worse than the worst results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[100/7324] Loss: 0.00000 Example/s: 83595.211 (Total examples: 204800)\n",
      "Epoch[1] Iteration[200/7324] Loss: 0.00000 Example/s: 96584.607 (Total examples: 409600)\n",
      "Epoch[1] Iteration[300/7324] Loss: 0.00000 Example/s: 101892.195 (Total examples: 614400)\n",
      "Epoch[1] Iteration[400/7324] Loss: 0.00000 Example/s: 104770.469 (Total examples: 819200)\n",
      "Epoch[1] Iteration[500/7324] Loss: 0.00000 Example/s: 106509.873 (Total examples: 1024000)\n",
      "Epoch[1] Iteration[600/7324] Loss: 0.00000 Example/s: 107752.193 (Total examples: 1228800)\n",
      "Epoch[1] Iteration[700/7324] Loss: 0.00000 Example/s: 108618.438 (Total examples: 1433600)\n",
      "Epoch[1] Iteration[800/7324] Loss: 0.00000 Example/s: 109312.444 (Total examples: 1638400)\n",
      "Epoch[1] Iteration[900/7324] Loss: 0.00000 Example/s: 109858.478 (Total examples: 1843200)\n",
      "Epoch[1] Iteration[1000/7324] Loss: 0.00000 Example/s: 110273.299 (Total examples: 2048000)\n",
      "Epoch[1] Iteration[1100/7324] Loss: 0.00000 Example/s: 110611.209 (Total examples: 2252800)\n",
      "Epoch[1] Iteration[1200/7324] Loss: 0.00000 Example/s: 110914.565 (Total examples: 2457600)\n",
      "Epoch[1] Iteration[1300/7324] Loss: 0.00000 Example/s: 111175.898 (Total examples: 2662400)\n",
      "Epoch[1] Iteration[1400/7324] Loss: 0.00000 Example/s: 111390.254 (Total examples: 2867200)\n",
      "Epoch[1] Iteration[1500/7324] Loss: 0.00000 Example/s: 111572.752 (Total examples: 3072000)\n",
      "Epoch[1] Iteration[1600/7324] Loss: 0.00000 Example/s: 111744.895 (Total examples: 3276800)\n",
      "Epoch[1] Iteration[1700/7324] Loss: 0.00000 Example/s: 111898.206 (Total examples: 3481600)\n",
      "Epoch[1] Iteration[1800/7324] Loss: 0.00000 Example/s: 112035.139 (Total examples: 3686400)\n",
      "Epoch[1] Iteration[1900/7324] Loss: 0.00000 Example/s: 112157.403 (Total examples: 3891200)\n",
      "Epoch[1] Iteration[2000/7324] Loss: 0.00000 Example/s: 112266.954 (Total examples: 4096000)\n",
      "Epoch[1] Iteration[2100/7324] Loss: 0.00000 Example/s: 112367.489 (Total examples: 4300800)\n",
      "Epoch[1] Iteration[2200/7324] Loss: 0.00000 Example/s: 112458.846 (Total examples: 4505600)\n",
      "Epoch[1] Iteration[2300/7324] Loss: 0.00000 Example/s: 112532.202 (Total examples: 4710400)\n",
      "Epoch[1] Iteration[2400/7324] Loss: 0.00000 Example/s: 112608.417 (Total examples: 4915200)\n",
      "Epoch[1] Iteration[2500/7324] Loss: 0.00000 Example/s: 112678.877 (Total examples: 5120000)\n",
      "Epoch[1] Iteration[2600/7324] Loss: 0.00000 Example/s: 112738.571 (Total examples: 5324800)\n",
      "Epoch[1] Iteration[2700/7324] Loss: 0.00000 Example/s: 112799.491 (Total examples: 5529600)\n",
      "Epoch[1] Iteration[2800/7324] Loss: 0.00000 Example/s: 112856.560 (Total examples: 5734400)\n",
      "Epoch[1] Iteration[2900/7324] Loss: 0.00000 Example/s: 112904.907 (Total examples: 5939200)\n",
      "Epoch[1] Iteration[3000/7324] Loss: 0.00000 Example/s: 112951.819 (Total examples: 6144000)\n",
      "Epoch[1] Iteration[3100/7324] Loss: 0.00000 Example/s: 112993.345 (Total examples: 6348800)\n",
      "Epoch[1] Iteration[3200/7324] Loss: 0.00000 Example/s: 113037.082 (Total examples: 6553600)\n",
      "Epoch[1] Iteration[3300/7324] Loss: 0.00000 Example/s: 113077.952 (Total examples: 6758400)\n",
      "Epoch[1] Iteration[3400/7324] Loss: 0.00000 Example/s: 113116.480 (Total examples: 6963200)\n",
      "Epoch[1] Iteration[3500/7324] Loss: 0.00000 Example/s: 113152.835 (Total examples: 7168000)\n",
      "Epoch[1] Iteration[3600/7324] Loss: 0.00000 Example/s: 113185.488 (Total examples: 7372800)\n",
      "Epoch[1] Iteration[3700/7324] Loss: 0.00000 Example/s: 113218.439 (Total examples: 7577600)\n",
      "Epoch[1] Iteration[3800/7324] Loss: 0.00000 Example/s: 113249.410 (Total examples: 7782400)\n",
      "Epoch[1] Iteration[3900/7324] Loss: 0.00000 Example/s: 113278.980 (Total examples: 7987200)\n",
      "Epoch[1] Iteration[4000/7324] Loss: 0.00000 Example/s: 113307.303 (Total examples: 8192000)\n",
      "Epoch[1] Iteration[4100/7324] Loss: 0.00000 Example/s: 113334.258 (Total examples: 8396800)\n",
      "Epoch[1] Iteration[4200/7324] Loss: 0.00000 Example/s: 113357.220 (Total examples: 8601600)\n",
      "Epoch[1] Iteration[4300/7324] Loss: 0.00000 Example/s: 113381.251 (Total examples: 8806400)\n",
      "Epoch[1] Iteration[4400/7324] Loss: 0.00000 Example/s: 113404.175 (Total examples: 9011200)\n",
      "Epoch[1] Iteration[4500/7324] Loss: 0.00000 Example/s: 113426.450 (Total examples: 9216000)\n",
      "Epoch[1] Iteration[4600/7324] Loss: 0.00000 Example/s: 113447.565 (Total examples: 9420800)\n",
      "Epoch[1] Iteration[4700/7324] Loss: 0.00000 Example/s: 113466.198 (Total examples: 9625600)\n",
      "Epoch[1] Iteration[4800/7324] Loss: 0.00000 Example/s: 113485.174 (Total examples: 9830400)\n",
      "Epoch[1] Iteration[4900/7324] Loss: 0.00000 Example/s: 113504.453 (Total examples: 10035200)\n",
      "Epoch[1] Iteration[5000/7324] Loss: 0.00000 Example/s: 113522.769 (Total examples: 10240000)\n",
      "Epoch[1] Iteration[5100/7324] Loss: 0.00000 Example/s: 113540.429 (Total examples: 10444800)\n",
      "Epoch[1] Iteration[5200/7324] Loss: 0.00000 Example/s: 113555.256 (Total examples: 10649600)\n",
      "Epoch[1] Iteration[5300/7324] Loss: 0.00000 Example/s: 113571.375 (Total examples: 10854400)\n",
      "Epoch[1] Iteration[5400/7324] Loss: 0.00000 Example/s: 113587.378 (Total examples: 11059200)\n",
      "Epoch[1] Iteration[5500/7324] Loss: 0.00000 Example/s: 113602.819 (Total examples: 11264000)\n",
      "Epoch[1] Iteration[5600/7324] Loss: 0.00000 Example/s: 113618.025 (Total examples: 11468800)\n",
      "Epoch[1] Iteration[5700/7324] Loss: 0.00000 Example/s: 113630.528 (Total examples: 11673600)\n",
      "Epoch[1] Iteration[5800/7324] Loss: 0.00000 Example/s: 113644.371 (Total examples: 11878400)\n",
      "Epoch[1] Iteration[5900/7324] Loss: 0.00000 Example/s: 109156.381 (Total examples: 12083200)\n",
      "Epoch[1] Iteration[6000/7324] Loss: 0.00000 Example/s: 103819.570 (Total examples: 12288000)\n",
      "Epoch[1] Iteration[6100/7324] Loss: 0.00000 Example/s: 99131.327 (Total examples: 12492800)\n",
      "Epoch[1] Iteration[6200/7324] Loss: 0.00000 Example/s: 94980.391 (Total examples: 12697600)\n",
      "Epoch[1] Iteration[6300/7324] Loss: 0.00000 Example/s: 91279.614 (Total examples: 12902400)\n",
      "Epoch[1] Iteration[6400/7324] Loss: 0.00000 Example/s: 87959.734 (Total examples: 13107200)\n",
      "Epoch[1] Iteration[6500/7324] Loss: 0.00000 Example/s: 84964.927 (Total examples: 13312000)\n",
      "Epoch[1] Iteration[6600/7324] Loss: 0.00000 Example/s: 82249.361 (Total examples: 13516800)\n",
      "Epoch[1] Iteration[6700/7324] Loss: 0.00000 Example/s: 79775.861 (Total examples: 13721600)\n",
      "Epoch[1] Iteration[6800/7324] Loss: 0.00000 Example/s: 77513.231 (Total examples: 13926400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:Current run is terminating due to exception: \n",
      "ERROR:Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1bea1bcb7882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dataload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-c347464731f8>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, batch_dataload, num_workers, use_cuDF)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_training(model, batch_dataload=True, num_workers=0, use_cuDF=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing tensor indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(tensor, rmin, rmax):\n",
    "    for i in range(rmin,rmax):\n",
    "        y = tensor[i]\n",
    "        y = y*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1820589, 3676645,  702164,  ..., 3846284, 3353801, 1632164],\n",
       "        [2279638,  770292,  542778,  ..., 2045485, 2845512,   32409],\n",
       "        [1798096,  263808,   23317,  ..., 3391318, 1897208,  752172],\n",
       "        ...,\n",
       "        [ 574563, 3338790, 3417787,  ..., 3613247, 3476169, 3302975],\n",
       "        [3099633, 3976291, 4115012,  ..., 2019696, 2479192, 3461823],\n",
       "        [3612167, 3337492, 3093107,  ..., 4115133, 3397563, 1619267]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.LongTensor(15000000, 45).random_(0, 2**22)\n",
    "features.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44 s ± 38.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit index(features,0,1000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46 s ± 42.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit index(features,13000000,14000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
