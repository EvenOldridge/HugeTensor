{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huge Tensor Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "I'm running this on the standard \n",
    "[RAPIDS docker containers](https://hub.docker.com/r/rapidsai/rapidsai) and also\n",
    "need the following `pip` dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.0.1 in /conda/envs/rapids/lib/python3.6/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytorch-ignite==0.1.2 in /conda/envs/rapids/lib/python3.6/site-packages (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.0.1 pytorch-ignite==0.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this on your local machine you should have most things installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict, OrderedDict\n",
    "#import glob\n",
    "import os\n",
    "#import re\n",
    "#import subprocess\n",
    "import time\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.handlers import EarlyStopping as IgniteEarlyStopping\n",
    "from ignite.metrics import Loss, Metric\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as torch_optim\n",
    "from torch.utils import data as torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETL - Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_quantiles = 20  # Used for computing histograms of continuous features\n",
    "num_features = 2 ** 22  # When hashing features range will be [0, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_dims = [600,600,600,600]\n",
    "\n",
    "device = 'cuda'\n",
    "dropout = None  # Can add dropout probability in [0, 1] here\n",
    "activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10000000\n",
    "\n",
    "train_batch_size = 2048\n",
    "validation_batch_size = train_batch_size*2\n",
    "\n",
    "log_interval = 250*2048//train_batch_size\n",
    "\n",
    "learning_rate = 0.01\n",
    "patience = 4\n",
    "lr_multiplier = 0.5\n",
    "max_epochs = 3  # Increase this for a more realistic training run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_hidden_layer(in_dim, out_dim, activation, dropout=None):\n",
    "    if dropout:\n",
    "        return nn.Sequential(nn.Linear(in_dim, out_dim), activation, nn.Dropout(p=dropout))\n",
    "    return nn.Sequential(nn.Linear(in_dim, out_dim), activation)\n",
    "\n",
    "\n",
    "class MortgageNetwork(nn.Module):\n",
    "    \"\"\"Mortgage Delinquency DNN.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        embedding_size,\n",
    "        hidden_dims,\n",
    "        use_cuda=True,\n",
    "        activation=nn.ReLU(),\n",
    "        dropout=None,\n",
    "        embedding_bag_mode='mean'\n",
    "    ):\n",
    "        super(MortgageNetwork, self).__init__()\n",
    "        self.input_size = num_features\n",
    "        self.embedding_size = embedding_size\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.modules.EmbeddingBag(self.input_size, self.embedding_size,\n",
    "                                                 mode=embedding_bag_mode)\n",
    "\n",
    "        if len(hidden_dims) > 0:\n",
    "            dims = [self.embedding_size] + hidden_dims\n",
    "            hidden_layers = [\n",
    "                _make_hidden_layer(dims[i], dims[i + 1], self.activation, self.dropout)\n",
    "                for i in range(len(dims) - 1)\n",
    "            ]\n",
    "            self.hidden_layers = nn.ModuleList(hidden_layers)\n",
    "            self.hidden_layers.extend([nn.Linear(dims[-1], 1)])\n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        out = self.embedding(x)\n",
    "        out = self.activation(out)\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, batch_dataload=False, num_workers=0, use_cuDF=False, shuffle=True):\n",
    "    # Data\n",
    "    if batch_dataload:\n",
    "        train_dataset = load_torch_dataset(os.path.join(out_dir, \"train\"), epoch_size,\n",
    "                                         batch_size=train_batch_size, use_cuDF=use_cuDF, num_files=1)\n",
    "#         validation_dataset = load_torch_dataset(os.path.join(out_dir, \"validation\"),\n",
    "#                                              batch_size=validation_batch_size, use_cuDF=use_cuDF, num_files=None)\n",
    "#         test_dataset = load_torch_dataset(os.path.join(out_dir, \"test\"),\n",
    "#                                              batch_size=validation_batch_size, use_cuDF=use_cuDF, num_files=None)\n",
    "\n",
    "        #train_loader = torch_data.DataLoader(train_dataset,\n",
    "        train_loader = batch_dataloader.BatchDataLoader(train_dataset,\n",
    "                                          shuffle=shuffle)\n",
    "#         validation_loader = batch_dataloader.BatchDataLoader(validation_dataset,\n",
    "#                                              num_workers=0)\n",
    "#         test_loader = batch_dataloader.BatchDataLoader(test_dataset,\n",
    "#                                             num_workers=0)\n",
    "    else:\n",
    "        train_dataset = load_torch_dataset(os.path.join(out_dir, \"train\"), epoch_size, shuffle_files=False)\n",
    "        validation_dataset = load_torch_dataset(os.path.join(out_dir, \"validation\"))\n",
    "        test_dataset = load_torch_dataset(os.path.join(out_dir, \"test\"))\n",
    "\n",
    "        train_loader = torch_data.DataLoader(train_dataset,\n",
    "                                         batch_size=train_batch_size,\n",
    "                                         num_workers=num_workers)\n",
    "        validation_loader = torch_data.DataLoader(validation_dataset,\n",
    "                                             batch_size=validation_batch_size,\n",
    "                                             num_workers=num_workers)\n",
    "        test_loader = torch_data.DataLoader(test_dataset,\n",
    "                                            batch_size=validation_batch_size,\n",
    "                                            num_workers=num_workers)        \n",
    "    # Optimizer\n",
    "    optimizer = torch_optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Loss Function\n",
    "    loss_fn = lambda pred, target: F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    trainer = create_supervised_trainer(model=model, optimizer=optimizer, loss_fn=loss_fn, device=device)\n",
    "\n",
    "    # Events\n",
    "    @trainer.on(Events.EPOCH_STARTED)\n",
    "    def timer(engine):\n",
    "        setattr(engine.state, \"epoch_start\", time.time())\n",
    "\n",
    "    num_epoch_batches = len(train_loader)\n",
    "    examples_per_epoch = num_epoch_batches * train_batch_size\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        iter = (engine.state.iteration - 1) % num_epoch_batches + 1\n",
    "        if iter % log_interval == 0:\n",
    "            epoch_time_elapsed = time.time() - engine.state.epoch_start\n",
    "            examples = engine.state.iteration * train_batch_size\n",
    "            epoch_examples_per_second = (examples - (engine.state.epoch - 1) * examples_per_epoch) / epoch_time_elapsed\n",
    "            print(\n",
    "                \"Epoch[{}] Iteration[{}/{}] Loss: {:.5f} Example/s: {:.3f} (Total examples: {})\".format(\n",
    "                    engine.state.epoch, iter, num_epoch_batches, engine.state.output,\n",
    "                    epoch_examples_per_second, examples))\n",
    "\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to load large dataset into GPU memory (Random LongTensor)\n",
    "#### Each load_torch_dataset function below represents a test I did to narrow down the cause of the issue.  Only run one of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random_batch_dataset as batch_dataset, batch_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function demonstrates the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial test: Create a dataset of random tensors that fit the model (45 wide longtensor, 1 wide float tensor target)\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.RandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This alternative function shows it's not an issue when the tensor is split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary test: Splitting the single tensor into 3 tensors removes the issue\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.MultiRandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function shows that when the tensors are created separately and then concatenated the issue returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third test: Concatenating the three tensors in the second test into a single tensor.  Issue shows up again\n",
    "def load_torch_dataset(root_path, num_samples=None, num_files=1, batch_size=1, use_cuDF=False):\n",
    "    return batch_dataset.ConcatRandomLongBatchDataset(num_samples = 15000000, batch_size = batch_size, cpu_mem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance issue\n",
    "Slowdown occurs around 12M examples.  Examples/s start getting slower and even when the epoch resets to access the memory that used to be fast performance is still poor and continues to degrade.\n",
    "\n",
    "You can see epoch 2 is about 1/2 as fast and performance keeps getting worse.\n",
    "\n",
    "I've tried to offset the dataloader so that it starts in that memory region and the slowdown is immediate and starts at around 25K examples/s, even worse than the worst results here.\n",
    "\n",
    "**Note, further testing has shown that this effect only occurs when shuffling the dataset**  Set shuffle=False and the slowdown doesn't occur so this likely has something to do with the random_perm indexing.  I've tried to test that below but it didn't seem to have the same impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = MortgageNetwork(num_features, embedding_size, hidden_dims,\n",
    "                        dropout=dropout, activation=activation, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling batch\n",
      "Epoch[1] Iteration[250/7324] Loss: 0.00000 Example/s: 112718.623 (Total examples: 512000)\n",
      "Epoch[1] Iteration[500/7324] Loss: 0.00000 Example/s: 113272.252 (Total examples: 1024000)\n",
      "Epoch[1] Iteration[750/7324] Loss: 0.00000 Example/s: 113484.826 (Total examples: 1536000)\n",
      "Epoch[1] Iteration[1000/7324] Loss: 0.00000 Example/s: 113583.441 (Total examples: 2048000)\n",
      "Epoch[1] Iteration[1250/7324] Loss: 0.00000 Example/s: 113610.944 (Total examples: 2560000)\n",
      "Epoch[1] Iteration[1500/7324] Loss: 0.00000 Example/s: 113637.484 (Total examples: 3072000)\n",
      "Epoch[1] Iteration[1750/7324] Loss: 0.00000 Example/s: 113676.748 (Total examples: 3584000)\n",
      "Epoch[1] Iteration[2000/7324] Loss: 0.00000 Example/s: 113687.516 (Total examples: 4096000)\n",
      "Epoch[1] Iteration[2250/7324] Loss: 0.00000 Example/s: 113704.248 (Total examples: 4608000)\n",
      "Epoch[1] Iteration[2500/7324] Loss: 0.00000 Example/s: 113719.250 (Total examples: 5120000)\n",
      "Epoch[1] Iteration[2750/7324] Loss: 0.00000 Example/s: 113729.681 (Total examples: 5632000)\n",
      "Epoch[1] Iteration[3000/7324] Loss: 0.00000 Example/s: 113744.068 (Total examples: 6144000)\n",
      "Epoch[1] Iteration[3250/7324] Loss: 0.00000 Example/s: 113741.798 (Total examples: 6656000)\n",
      "Epoch[1] Iteration[3500/7324] Loss: 0.00000 Example/s: 113749.611 (Total examples: 7168000)\n",
      "Epoch[1] Iteration[3750/7324] Loss: 0.00000 Example/s: 113757.621 (Total examples: 7680000)\n",
      "Epoch[1] Iteration[4000/7324] Loss: 0.00000 Example/s: 113766.566 (Total examples: 8192000)\n",
      "Epoch[1] Iteration[4250/7324] Loss: 0.00000 Example/s: 113775.308 (Total examples: 8704000)\n",
      "Epoch[1] Iteration[4500/7324] Loss: 0.00000 Example/s: 113772.604 (Total examples: 9216000)\n",
      "Epoch[1] Iteration[4750/7324] Loss: 0.00000 Example/s: 113777.572 (Total examples: 9728000)\n",
      "Epoch[1] Iteration[5000/7324] Loss: 0.00000 Example/s: 113784.333 (Total examples: 10240000)\n",
      "Epoch[1] Iteration[5250/7324] Loss: 0.00000 Example/s: 113788.402 (Total examples: 10752000)\n",
      "Epoch[1] Iteration[5500/7324] Loss: 0.00000 Example/s: 113793.794 (Total examples: 11264000)\n",
      "Epoch[1] Iteration[5750/7324] Loss: 0.00000 Example/s: 113798.435 (Total examples: 11776000)\n",
      "Epoch[1] Iteration[6000/7324] Loss: 0.00000 Example/s: 103939.585 (Total examples: 12288000)\n",
      "Epoch[1] Iteration[6250/7324] Loss: 0.00000 Example/s: 93163.779 (Total examples: 12800000)\n",
      "Epoch[1] Iteration[6500/7324] Loss: 0.00000 Example/s: 85028.456 (Total examples: 13312000)\n",
      "Epoch[1] Iteration[6750/7324] Loss: 0.00000 Example/s: 78668.321 (Total examples: 13824000)\n",
      "Epoch[1] Iteration[7000/7324] Loss: 0.00000 Example/s: 73557.990 (Total examples: 14336000)\n",
      "Epoch[1] Iteration[7250/7324] Loss: 0.00000 Example/s: 69363.374 (Total examples: 14848000)\n",
      "shuffling batch\n",
      "Epoch[2] Iteration[250/7324] Loss: 0.00000 Example/s: 66726.517 (Total examples: 15511552)\n",
      "Epoch[2] Iteration[500/7324] Loss: 0.00000 Example/s: 66780.492 (Total examples: 16023552)\n",
      "Epoch[2] Iteration[750/7324] Loss: 0.00000 Example/s: 66749.161 (Total examples: 16535552)\n",
      "Epoch[2] Iteration[1000/7324] Loss: 0.00000 Example/s: 66732.043 (Total examples: 17047552)\n",
      "Epoch[2] Iteration[1250/7324] Loss: 0.00000 Example/s: 66745.786 (Total examples: 17559552)\n",
      "Epoch[2] Iteration[1500/7324] Loss: 0.00000 Example/s: 66752.375 (Total examples: 18071552)\n",
      "Epoch[2] Iteration[1750/7324] Loss: 0.00000 Example/s: 66754.770 (Total examples: 18583552)\n",
      "Epoch[2] Iteration[2000/7324] Loss: 0.00000 Example/s: 66765.626 (Total examples: 19095552)\n",
      "Epoch[2] Iteration[2250/7324] Loss: 0.00000 Example/s: 66770.662 (Total examples: 19607552)\n",
      "Epoch[2] Iteration[2500/7324] Loss: 0.00000 Example/s: 66771.590 (Total examples: 20119552)\n",
      "Epoch[2] Iteration[2750/7324] Loss: 0.00000 Example/s: 66776.573 (Total examples: 20631552)\n",
      "Epoch[2] Iteration[3000/7324] Loss: 0.00000 Example/s: 66782.078 (Total examples: 21143552)\n",
      "Epoch[2] Iteration[3250/7324] Loss: 0.00000 Example/s: 66797.738 (Total examples: 21655552)\n",
      "Epoch[2] Iteration[3500/7324] Loss: 0.00000 Example/s: 66789.715 (Total examples: 22167552)\n",
      "Epoch[2] Iteration[3750/7324] Loss: 0.00000 Example/s: 66786.335 (Total examples: 22679552)\n",
      "Epoch[2] Iteration[4000/7324] Loss: 0.00000 Example/s: 66787.614 (Total examples: 23191552)\n",
      "Epoch[2] Iteration[4250/7324] Loss: 0.00000 Example/s: 66779.108 (Total examples: 23703552)\n",
      "Epoch[2] Iteration[4500/7324] Loss: 0.00000 Example/s: 66781.312 (Total examples: 24215552)\n",
      "Epoch[2] Iteration[4750/7324] Loss: 0.00000 Example/s: 66782.049 (Total examples: 24727552)\n",
      "Epoch[2] Iteration[5000/7324] Loss: 0.00000 Example/s: 66781.346 (Total examples: 25239552)\n",
      "Epoch[2] Iteration[5250/7324] Loss: 0.00000 Example/s: 66775.776 (Total examples: 25751552)\n",
      "Epoch[2] Iteration[5500/7324] Loss: 0.00000 Example/s: 66783.616 (Total examples: 26263552)\n",
      "Epoch[2] Iteration[5750/7324] Loss: 0.00000 Example/s: 66783.355 (Total examples: 26775552)\n",
      "Epoch[2] Iteration[6000/7324] Loss: 0.00000 Example/s: 64003.105 (Total examples: 27287552)\n",
      "Epoch[2] Iteration[6250/7324] Loss: 0.00000 Example/s: 60618.392 (Total examples: 27799552)\n",
      "Epoch[2] Iteration[6500/7324] Loss: 0.00000 Example/s: 57796.624 (Total examples: 28311552)\n",
      "Epoch[2] Iteration[6750/7324] Loss: 0.00000 Example/s: 55408.488 (Total examples: 28823552)\n",
      "Epoch[2] Iteration[7000/7324] Loss: 0.00000 Example/s: 53361.266 (Total examples: 29335552)\n",
      "Epoch[2] Iteration[7250/7324] Loss: 0.00000 Example/s: 51586.771 (Total examples: 29847552)\n",
      "shuffling batch\n",
      "Epoch[3] Iteration[250/7324] Loss: 0.00000 Example/s: 50471.020 (Total examples: 30511104)\n",
      "Epoch[3] Iteration[500/7324] Loss: 0.00000 Example/s: 50332.755 (Total examples: 31023104)\n",
      "Epoch[3] Iteration[750/7324] Loss: 0.00000 Example/s: 50324.743 (Total examples: 31535104)\n",
      "Epoch[3] Iteration[1000/7324] Loss: 0.00000 Example/s: 50310.858 (Total examples: 32047104)\n",
      "Epoch[3] Iteration[1250/7324] Loss: 0.00000 Example/s: 50309.144 (Total examples: 32559104)\n",
      "Epoch[3] Iteration[1500/7324] Loss: 0.00000 Example/s: 50312.269 (Total examples: 33071104)\n",
      "Epoch[3] Iteration[1750/7324] Loss: 0.00000 Example/s: 50308.271 (Total examples: 33583104)\n",
      "Epoch[3] Iteration[2000/7324] Loss: 0.00000 Example/s: 50296.914 (Total examples: 34095104)\n",
      "Epoch[3] Iteration[2250/7324] Loss: 0.00000 Example/s: 50288.113 (Total examples: 34607104)\n",
      "Epoch[3] Iteration[2500/7324] Loss: 0.00000 Example/s: 50280.340 (Total examples: 35119104)\n",
      "Epoch[3] Iteration[2750/7324] Loss: 0.00000 Example/s: 50277.311 (Total examples: 35631104)\n",
      "Epoch[3] Iteration[3000/7324] Loss: 0.00000 Example/s: 50273.751 (Total examples: 36143104)\n",
      "Epoch[3] Iteration[3250/7324] Loss: 0.00000 Example/s: 50266.253 (Total examples: 36655104)\n",
      "Epoch[3] Iteration[3500/7324] Loss: 0.00000 Example/s: 50267.080 (Total examples: 37167104)\n",
      "Epoch[3] Iteration[3750/7324] Loss: 0.00000 Example/s: 50261.955 (Total examples: 37679104)\n",
      "Epoch[3] Iteration[4000/7324] Loss: 0.00000 Example/s: 50255.413 (Total examples: 38191104)\n",
      "Epoch[3] Iteration[4250/7324] Loss: 0.00000 Example/s: 50256.394 (Total examples: 38703104)\n",
      "Epoch[3] Iteration[4500/7324] Loss: 0.00000 Example/s: 50259.593 (Total examples: 39215104)\n",
      "Epoch[3] Iteration[4750/7324] Loss: 0.00000 Example/s: 50254.076 (Total examples: 39727104)\n",
      "Epoch[3] Iteration[5000/7324] Loss: 0.00000 Example/s: 50251.947 (Total examples: 40239104)\n",
      "Epoch[3] Iteration[5250/7324] Loss: 0.00000 Example/s: 50253.488 (Total examples: 40751104)\n",
      "Epoch[3] Iteration[5500/7324] Loss: 0.00000 Example/s: 50255.439 (Total examples: 41263104)\n",
      "Epoch[3] Iteration[5750/7324] Loss: 0.00000 Example/s: 50256.087 (Total examples: 41775104)\n",
      "Epoch[3] Iteration[6000/7324] Loss: 0.00000 Example/s: 49014.391 (Total examples: 42287104)\n",
      "Epoch[3] Iteration[6250/7324] Loss: 0.00000 Example/s: 47430.464 (Total examples: 42799104)\n",
      "Epoch[3] Iteration[6500/7324] Loss: 0.00000 Example/s: 46056.565 (Total examples: 43311104)\n",
      "Epoch[3] Iteration[6750/7324] Loss: 0.00000 Example/s: 44853.708 (Total examples: 43823104)\n",
      "Epoch[3] Iteration[7000/7324] Loss: 0.00000 Example/s: 43791.694 (Total examples: 44335104)\n",
      "Epoch[3] Iteration[7250/7324] Loss: 0.00000 Example/s: 42847.191 (Total examples: 44847104)\n"
     ]
    }
   ],
   "source": [
    "run_training(model, batch_dataload=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing tensor indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(tensor, rmin, rmax):\n",
    "    for i in range(rmin,rmax):\n",
    "        y = tensor[i:i+2048]\n",
    "        y = y*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.empty(15000000, 45, dtype=torch.int64, device='cuda').random_(0, 2**22)\n",
    "#features.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 28 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%time index(features,0,1000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 68 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%time index(features,13000000,14000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randperm(len(features), dtype=torch.int64, device='cuda')\n",
    "features = features[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 20 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%time index(features,0,1000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 32 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%time index(features,13000000,14000000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
